SEED: 42
DEVICE: [0, 1]
# DATASET
DATA_TRAIN: ./data/train.csv
NUM_WORKERS: 8

# training
TRAIN_DATASET:
    PY: datasets.dataset
    CLASS: SteelDataset
    ARGS:
        root_dir: ./data/train_images/
        phase: train
        encoder_name: efficientnet-b1
        pretrained: imagenet

VALID_DATASET:
    PY: datasets.dataset
    CLASS: SteelDataset
    ARGS:
        root_dir: ./data/train_images/
        phase: valid
        encoder_name: efficientnet-b1
        pretrained: imagenet
TEST_DATASET:
    PY: datasets.dataset
    CLASS: SteelDataset
    ARGS:
        root_dir: ./data/test_images/
        phase: valid
        encoder_name: efficientnet-b1
        pretrained: imagenet

TRAIN_DATALOADER:
    PY: torch.utils.data
    CLASS: DataLoader
    ARGS:
        batch_size: 22
        shuffle: True
        num_workers: 16
        pin_memory: True

VALID_DATALOADER:
    PY: torch.utils.data
    CLASS: DataLoader
    ARGS:
        batch_size: 22
        shuffle: False
        num_workers: 16
        pin_memory: True
TEST_DATALOADER:
    PY: torch.utils.data
    CLASS: DataLoader
    ARGS:
        batch_size: 4
        shuffle: False
        num_workers: 8
        pin_memory: True

MODEL:
    PY: modules
    CLASS: Unet
    ARGS:
        encoder_name: efficientnet-b1
        encoder_weights: imagenet
        classes: 4
        activation: softmax


CRITERION:
    PY: modules.utils.losses
    CLASS: BCEDiceLoss
    ARGS:
        eps: 1.0


OPTIMIZER:
    PY: torch.optim
    CLASS: Adam
    ARGS:
        lr: 0.0001
        weight_decay: 0.000005

SCHEDULER:
    PY: torch.optim.lr_scheduler
    CLASS: ReduceLROnPlateau
    ARGS:
        factor: 0.15
        patience: 2

GRADIENT_ACCUMULATION_STEPS: 1
GRADIENT_CLIPPING: 0.1
NUM_EPOCH: 50
EARLY_STOPPING: 10
VALIDATION_FREQUENCY: 5
SAVED_PERIOD: 5
CHECKPOINT_DIR: ./saved
RESUME_PATH:
